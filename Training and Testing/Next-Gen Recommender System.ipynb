{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNAJmNkCKEqGGXYwhRXGCR9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ecg-5VVzcFqj","executionInfo":{"status":"ok","timestamp":1731818821576,"user_tz":-330,"elapsed":27890,"user":{"displayName":"AMALAN JOSEPH J","userId":"10758883528686623989"}},"outputId":"af928b09-3b32-4244-b2c2-e8b24831cc08"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3127 - loss: 1.5832 - val_accuracy: 0.8150 - val_loss: 0.8026\n","Epoch 2/20\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6968 - loss: 0.7833 - val_accuracy: 0.9700 - val_loss: 0.3546\n","Epoch 3/20\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8506 - loss: 0.4408 - val_accuracy: 1.0000 - val_loss: 0.1324\n","Epoch 4/20\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9287 - loss: 0.2512 - val_accuracy: 1.0000 - val_loss: 0.0513\n","Epoch 5/20\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.1411 - val_accuracy: 1.0000 - val_loss: 0.0205\n","Epoch 6/20\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9784 - loss: 0.0894 - val_accuracy: 1.0000 - val_loss: 0.0091\n","Epoch 7/20\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.0648 - val_accuracy: 1.0000 - val_loss: 0.0063\n","Epoch 8/20\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0475 - val_accuracy: 1.0000 - val_loss: 0.0038\n","Epoch 9/20\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9934 - loss: 0.0338 - val_accuracy: 1.0000 - val_loss: 0.0021\n","Epoch 10/20\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.0336 - val_accuracy: 1.0000 - val_loss: 0.0015\n","Epoch 11/20\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0261 - val_accuracy: 1.0000 - val_loss: 0.0011\n","Epoch 12/20\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9934 - loss: 0.0229 - val_accuracy: 1.0000 - val_loss: 7.7337e-04\n","Epoch 13/20\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9963 - loss: 0.0187 - val_accuracy: 1.0000 - val_loss: 4.0359e-04\n","Epoch 14/20\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9943 - loss: 0.0188 - val_accuracy: 1.0000 - val_loss: 4.1601e-04\n","Epoch 15/20\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9962 - loss: 0.0174 - val_accuracy: 1.0000 - val_loss: 3.7276e-04\n","Epoch 16/20\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9973 - loss: 0.0119 - val_accuracy: 1.0000 - val_loss: 2.3109e-04\n","Epoch 17/20\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9961 - loss: 0.0120 - val_accuracy: 1.0000 - val_loss: 2.3029e-04\n","Epoch 18/20\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9958 - loss: 0.0155 - val_accuracy: 1.0000 - val_loss: 2.3721e-04\n","Epoch 19/20\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9962 - loss: 0.0120 - val_accuracy: 1.0000 - val_loss: 2.4354e-04\n","Epoch 20/20\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9975 - loss: 0.0103 - val_accuracy: 1.0000 - val_loss: 9.9329e-05\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.9515e-05\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 9.932860848493874e-05\n","Test Accuracy: 1.0\n","Model saved as 'a_to_z_supermarket_model.h5'\n"]}],"source":["from sklearn.preprocessing import LabelEncoder, StandardScaler\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","import pandas as pd\n","\n","dataset_path = \"a_to_z_supermarket_transactions.csv\"\n","data = pd.read_csv(dataset_path)\n","\n","label_encoder_customer = LabelEncoder()\n","label_encoder_product = LabelEncoder()\n","label_encoder_category = LabelEncoder()\n","\n","data['customer_id'] = label_encoder_customer.fit_transform(data['customer_id'])\n","data['product_id'] = label_encoder_product.fit_transform(data['product_id'])\n","data['category'] = label_encoder_category.fit_transform(data['category'])\n","\n","X = data[['customer_id', 'product_id', 'category', 'quantity', 'price', 'total_spent']]\n","y = data['category']\n","\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","y = pd.get_dummies(y)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","model = Sequential([\n","    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n","    Dropout(0.2),\n","    Dense(32, activation='relu'),\n","    Dropout(0.2),\n","    Dense(y_train.shape[1], activation='softmax')\n","])\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n","\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print(f\"Test Loss: {loss}\")\n","print(f\"Test Accuracy: {accuracy}\")\n","\n","model.save(\"a_to_z_supermarket_model.h5\")\n","print(\"Model saved as 'a_to_z_supermarket_model.h5'\")\n"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from tensorflow.keras.models import load_model\n","from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n","import logging\n","\n","logging.basicConfig(level=logging.INFO)\n","\n","model_path = \"/content/a_to_z_supermarket_model.h5\"\n","model = load_model(model_path)\n","\n","dataset_path = \"a_to_z_supermarket_transactions.csv\"\n","data = pd.read_csv(dataset_path)\n","\n","label_encoder_customer = LabelEncoder()\n","data['customer_id'] = label_encoder_customer.fit_transform(data['customer_id'])\n","\n","label_encoder_product = LabelEncoder()\n","data['product_id'] = label_encoder_product.fit_transform(data['product_id'])\n","\n","category_encoder = LabelEncoder()\n","data['category'] = category_encoder.fit_transform(data['category'])\n","\n","supplementary_products = {\n","    \"Bread\": [\"Jam\", \"Butter\", \"Cheese\"],\n","    \"Milk\": [\"Sugar\", \"Coffee\", \"Tea\"],\n","    \"Rice\": [\"Curry Powder\", \"Vegetables\", \"Spices\"],\n","}\n","\n","default_supplementary_products = {\n","    \"Fruits\": [\"Vegetables\"],\n","    \"Vegetables\": [\"Fruits\"],\n","    \"Snacks\": [\"Beverages\"],\n","    \"Beverages\": [\"Bakery\", \"Dairy\"],\n","    \"Bakery\": [\"Snacks\"],\n","    \"Dairy\": [\"Beverages\"],\n","    \"Pasta\": [\"Sauce\"],\n","    \"Cereal\": [\"Milk\"],\n","    \"Tea\": [\"Biscuits\"],\n","    \"Coffee\": [\"Sugar\"],\n","    \"Chips\": [\"Salsa\"],\n","    \"Frozen Foods\": [\"Sauces\"],\n","    \"Chicken\": [\"Spices\"],\n","    \"Fish\": [\"Lemon\"],\n","    \"Cheese\": [\"Crackers\"],\n","    \"Yogurt\": [\"Fruits\"],\n","    \"Ice Cream\": [\"Toppings\"],\n","    \"Wine\": [\"Cheese\"],\n","    \"Chocolates\": [\"Gift Wrapping\"],\n","    \"Bread\": [\"Deli Meats\"],\n","    \"Vegetables\": [\"Dip\"],\n","    \"Eggs\": [\"Bacon\"],\n","    \"Spaghetti\": [\"Meatballs\"],\n","    \"Soup\": [\"Croutons\"],\n","    \"Pizza\": [\"Soft Drinks\"],\n","    \"Juices\": [\"Cookies\"],\n","}\n","\n","def get_customer_history(customer_id):\n","    customer_id_encoded = label_encoder_customer.transform([customer_id])[0]\n","    customer_history = data[data['customer_id'] == customer_id_encoded]\n","    if customer_history.empty:\n","        logging.warning(f\"No purchase history found for customer ID: {customer_id}\")\n","    return customer_history\n","\n","def compute_parameters(history):\n","    total_purchases = len(history)\n","    favorite_category = history['category'].mode()[0]\n","    total_spent = history['total_spent'].sum()\n","    average_quantity = history['quantity'].mean()\n","    most_expensive_purchase = history['price'].max()\n","    average_price = history['price'].mean()\n","    return [total_purchases, favorite_category, total_spent, average_quantity, most_expensive_purchase, average_price]\n","\n","def recommend_products(customer_id):\n","    customer_history = get_customer_history(customer_id)\n","    if customer_history.empty:\n","        return \"No purchase history found for this customer.\"\n","\n","    parameters = compute_parameters(customer_history)\n","    logging.info(f\"Computed Parameters: {parameters}\")\n","\n","    scaler = MinMaxScaler()\n","    parameters_scaled = scaler.fit_transform(np.array(parameters).reshape(1, -1))\n","\n","    prediction = model.predict(parameters_scaled)\n","    recommended_category_index = np.argmax(prediction)\n","\n","    recommended_category = category_encoder.inverse_transform([recommended_category_index])[0]\n","    logging.info(f\"Recommended Category: {recommended_category}\")\n","\n","    supplementary_items = supplementary_products.get(recommended_category, [])\n","    if not supplementary_items:\n","        supplementary_items = default_supplementary_products.get(recommended_category, [])\n","\n","    if supplementary_items:\n","        logging.info(f\"Suggested supplementary products: {', '.join(supplementary_items)}\")\n","    else:\n","        logging.info(\"No supplementary products found for the recommended category.\")\n","\n","    return recommended_category, supplementary_items\n","\n","customer_id = input(\"Enter Customer ID: \")\n","recommended_category, supplementary_items = recommend_products(customer_id)\n","print(f\"Recommended Category: {recommended_category}\")\n","print(f\"Suggested supplementary products: {', '.join(supplementary_items)}\" if supplementary_items else \"No supplementary products available.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LM4kak5fckVB","executionInfo":{"status":"ok","timestamp":1731818845524,"user_tz":-330,"elapsed":7716,"user":{"displayName":"AMALAN JOSEPH J","userId":"10758883528686623989"}},"outputId":"72eed1ec-b52c-49a5-fa45-dad4cca4f2f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Enter Customer ID: C00744\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n","Recommended Category: Dairy\n","Suggested supplementary products: Beverages\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zkSWgNV7fNNl","executionInfo":{"status":"ok","timestamp":1731820390854,"user_tz":-330,"elapsed":3446,"user":{"displayName":"AMALAN JOSEPH J","userId":"10758883528686623989"}},"outputId":"1a956218-b0f6-41c8-ab17-3007b0afeb75"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]}]}
